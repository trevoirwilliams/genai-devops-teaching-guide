name: "Azure OpenAI Chat Completion"
description: "Calls Azure OpenAI chat completions endpoint and writes the assistant message to a file."

inputs:
  endpoint:
    description: "Azure OpenAI endpoint (e.g., https://xxxx.openai.azure.com)"
    required: true
  api_key:
    description: "Azure OpenAI API Key"
    required: true
  deployment:
    description: "Azure OpenAI deployment name"
    required: true
  api_version:
    description: "Azure OpenAI API version"
    required: false
    default: "2024-02-15-preview"
  system_prompt_file:
    description: "Path to system prompt text/markdown file"
    required: true
  user_input_file:
    description: "Path to user input file (usually JSON)"
    required: true
  output_file:
    description: "Path to write model output (markdown/text)"
    required: false
    default: "release-notes.md"
  temperature:
    description: "Model temperature (0.0-2.0). Lower is more deterministic."
    required: false
    default: "0.1"

outputs:
  response_path:
    description: "Path to raw response JSON file"
    value: ${{ steps.call.outputs.response_path }}
  output_path:
    description: "Path to generated output file"
    value: ${{ steps.call.outputs.output_path }}
  http_status:
    description: "HTTP status code from Azure OpenAI"
    value: ${{ steps.call.outputs.http_status }}
  duration_seconds:
    description: "Duration of the successful model call in seconds"
    value: ${{ steps.call.outputs.duration_seconds }}
  total_tokens:
    description: "Total tokens used (prompt + completion)"
    value: ${{ steps.call.outputs.total_tokens }}
  prompt_tokens:
    description: "Prompt tokens used"
    value: ${{ steps.call.outputs.prompt_tokens }}
  completion_tokens:
    description: "Completion tokens used"
    value: ${{ steps.call.outputs.completion_tokens }}

runs:
  using: "composite"
  steps:
    - name: Validate inputs and dependencies
      shell: bash
      run: |
        set -euo pipefail
        command -v jq >/dev/null 2>&1 || (echo "jq is required but not installed." && exit 1)

        [[ -f "${{ inputs.system_prompt_file }}" ]] || (echo "System prompt file not found: ${{ inputs.system_prompt_file }}" && exit 1)
        [[ -f "${{ inputs.user_input_file }}" ]] || (echo "User input file not found: ${{ inputs.user_input_file }}" && exit 1)

        [[ -n "${{ inputs.endpoint }}" ]] || (echo "Missing endpoint input" && exit 1)
        [[ -n "${{ inputs.api_key }}" ]] || (echo "Missing api_key input" && exit 1)
        [[ -n "${{ inputs.deployment }}" ]] || (echo "Missing deployment input" && exit 1)

    - name: Call Azure OpenAI
      id: call
      shell: bash
      run: |
        set -euo pipefail

        # Mask key so it won't appear in logs
        echo "::add-mask::${{ inputs.api_key }}"

        SYSTEM_PROMPT="$(cat "${{ inputs.system_prompt_file }}")"
        USER_INPUT="$(cat "${{ inputs.user_input_file }}")"

        PROMPT_SIZE=$(wc -c < "${{ inputs.system_prompt_file }}")
        INPUT_SIZE=$(wc -c < "${{ inputs.user_input_file }}")

        echo "System prompt size: ${PROMPT_SIZE} bytes"
        echo "User input size: ${INPUT_SIZE} bytes"

        MAX_INPUT_BYTES=25000
        DURATION=0
        http_code=0

        if [ "$INPUT_SIZE" -gt "$MAX_INPUT_BYTES" ]; then
          echo "Input exceeds ${MAX_INPUT_BYTES} bytes. Refusing to call model."
          exit 1
        fi

        BODY="$(jq -n \
          --arg system "$SYSTEM_PROMPT" \
          --arg user "$USER_INPUT" \
          --argjson temp "${{ inputs.temperature }}" \
          '{
            messages: [
              {role:"system", content:$system},
              {role:"user", content:$user}
            ],
            temperature: $temp
          }')"

        RESPONSE_FILE=".aoai.response.json"
        OUTPUT_FILE="${{ inputs.output_file }}"

        MAX_RETRIES=3
        ATTEMPT=1
        SLEEP_SECONDS=2

        while true; do
          START_TIME=$(date +%s)

          http_code=$(curl -sS -o "$RESPONSE_FILE" -w "%{http_code}" \
            -X POST \
            "${{ inputs.endpoint }}/openai/deployments/${{ inputs.deployment }}/chat/completions?api-version=${{ inputs.api_version }}" \
            -H "Content-Type: application/json" \
            -H "api-key: ${{ inputs.api_key }}" \
            -d "$BODY" || true)

          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))

          echo "Model call duration: ${DURATION}s"

          if [[ "$http_code" -ge 200 && "$http_code" -lt 300 ]]; then
            break
          fi

          if [[ "$ATTEMPT" -ge "$MAX_RETRIES" ]]; then
            echo "Azure OpenAI call failed after ${ATTEMPT} attempts (HTTP $http_code)"
            jq -c '.' "$RESPONSE_FILE" || true
            exit 1
          fi

          echo "Retry ${ATTEMPT}/${MAX_RETRIES} after ${SLEEP_SECONDS}s (HTTP $http_code)"
          sleep "$SLEEP_SECONDS"

          ATTEMPT=$((ATTEMPT + 1))
          SLEEP_SECONDS=$((SLEEP_SECONDS * 2))
        done


        jq -r '.choices[0].message.content // empty' "$RESPONSE_FILE" > "$OUTPUT_FILE"
        if [[ ! -s "$OUTPUT_FILE" ]]; then
          echo "Azure OpenAI returned empty output."
          exit 1
        fi

        PROMPT_TOKENS=$(jq -r '.usage.prompt_tokens // 0' "$RESPONSE_FILE")
        COMPLETION_TOKENS=$(jq -r '.usage.completion_tokens // 0' "$RESPONSE_FILE")
        TOTAL_TOKENS=$(jq -r '.usage.total_tokens // 0' "$RESPONSE_FILE")

        echo "Prompt tokens: $PROMPT_TOKENS"
        echo "Completion tokens: $COMPLETION_TOKENS"
        echo "Total tokens: $TOTAL_TOKENS"

        echo "http_status=${http_code}" >> "$GITHUB_OUTPUT"
        echo "duration_seconds=${DURATION}" >> "$GITHUB_OUTPUT"
        echo "total_tokens=${TOTAL_TOKENS}" >> "$GITHUB_OUTPUT"
        echo "prompt_tokens=${PROMPT_TOKENS}" >> "$GITHUB_OUTPUT"
        echo "completion_tokens=${COMPLETION_TOKENS}" >> "$GITHUB_OUTPUT"

        cat <<EOF > ai-telemetry.json
        {
          "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
          "prompt_size_bytes": ${PROMPT_SIZE},
          "input_size_bytes": ${INPUT_SIZE},
          "duration_seconds": ${DURATION},
          "http_status": ${http_code},
          "prompt_tokens": ${PROMPT_TOKENS},
          "completion_tokens": ${COMPLETION_TOKENS},
          "total_tokens": ${TOTAL_TOKENS}
        }